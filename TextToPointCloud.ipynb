{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "V100",
      "authorship_tag": "ABX9TyNm1YbTLZdYRQ0gB32JapCL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cagBRT/PointCloud/blob/main/TextToPointCloud.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio\n"
      ],
      "metadata": {
        "id": "kiHAXyg3p6S7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/openai/point-e -q\n"
      ],
      "metadata": {
        "id": "E-oN36J9qLz5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "import torch\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "from point_e.diffusion.configs import DIFFUSION_CONFIGS, diffusion_from_config\n",
        "from point_e.diffusion.sampler import PointCloudSampler\n",
        "from point_e.models.download import load_checkpoint\n",
        "from point_e.models.configs import MODEL_CONFIGS, model_from_config\n",
        "from point_e.util.plotting import plot_point_cloud"
      ],
      "metadata": {
        "id": "JkM-encqqOYJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "22hihEQJp2XU"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "print('creating base model...')\n",
        "base_name = 'base40M-textvec'\n",
        "base_model = model_from_config(MODEL_CONFIGS[base_name], device)\n",
        "base_model.eval()\n",
        "base_diffusion = diffusion_from_config(DIFFUSION_CONFIGS[base_name])\n",
        "\n",
        "print('creating upsample model...')\n",
        "upsampler_model = model_from_config(MODEL_CONFIGS['upsample'], device)\n",
        "upsampler_model.eval()\n",
        "upsampler_diffusion = diffusion_from_config(DIFFUSION_CONFIGS['upsample'])\n",
        "\n",
        "print('downloading base checkpoint...')\n",
        "base_model.load_state_dict(load_checkpoint(base_name, device))\n",
        "\n",
        "print('downloading upsampler checkpoint...')\n",
        "upsampler_model.load_state_dict(load_checkpoint('upsample', device))\n",
        "\n",
        "sampler = PointCloudSampler(\n",
        "    device=device,\n",
        "    models=[base_model, upsampler_model],\n",
        "    diffusions=[base_diffusion, upsampler_diffusion],\n",
        "    num_points=[1024, 4096 - 1024],\n",
        "    aux_channels=['R', 'G', 'B'],\n",
        "    guidance_scale=[3.0, 0.0],\n",
        "    model_kwargs_key_filter=('texts', ''), # Do not condition the upsampler at all\n",
        ")\n",
        "\n",
        "def inference(prompt):\n",
        "    samples = None\n",
        "    for x in sampler.sample_batch_progressive(batch_size=1, model_kwargs=dict(texts=[prompt])):\n",
        "        samples = x\n",
        "    pc = sampler.output_to_point_clouds(samples)[0]\n",
        "    pc = sampler.output_to_point_clouds(samples)[0]\n",
        "    colors=(238, 75, 43)\n",
        "    fig = go.Figure(\n",
        "        data=[\n",
        "            go.Scatter3d(\n",
        "                x=pc.coords[:,0], y=pc.coords[:,1], z=pc.coords[:,2],\n",
        "                mode='markers',\n",
        "                marker=dict(\n",
        "                  size=2,\n",
        "                  color=['rgb({},{},{})'.format(r,g,b) for r,g,b in zip(pc.channels[\"R\"], pc.channels[\"G\"], pc.channels[\"B\"])],\n",
        "              )\n",
        "            )\n",
        "        ],\n",
        "        layout=dict(\n",
        "            scene=dict(\n",
        "                xaxis=dict(visible=False),\n",
        "                yaxis=dict(visible=False),\n",
        "                zaxis=dict(visible=False)\n",
        "            )\n",
        "        ),\n",
        "    )\n",
        "    return fig\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=inference,\n",
        "    inputs=\"text\",\n",
        "    outputs=gr.Plot(),\n",
        "    examples=[\n",
        "        [\"a red motorcycle\"],\n",
        "        [\"a RED pumpkin\"],\n",
        "        [\"a yellow rubber duck\"]\n",
        "    ],\n",
        "    title=\"Point-E demo: text to 3D\",\n",
        "    description=\"\"\"Generated 3D Point Clouds with [Point-E](https://github.com/openai/point-e/tree/main). This demo uses a small, worse quality text-to-3D model to produce 3D point clouds directly from text descriptions.\n",
        "    Check out the [notebook](https://github.com/openai/point-e/blob/main/point_e/examples/text2pointcloud.ipynb).\n",
        "\"\"\"\n",
        ")\n",
        "demo.queue(max_size=30)\n",
        "demo.launch(debug=True)"
      ]
    }
  ]
}