{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPC6F7AOH9lykS/ofyjvFSQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cagBRT/PointCloud/blob/main/Depth_Maps.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone the entire repo.\n",
        "!git clone -l -s https://github.com/cagBRT/PointCloud.git cloned-repo\n",
        "%cd cloned-repo"
      ],
      "metadata": {
        "id": "6mNMJazsajMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image"
      ],
      "metadata": {
        "id": "IwxNypgGalOm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Albumentations is a Python library for performing data augmentation for computer vision. It supports various computer vision tasks such as image classification, object detection, segmentation, and keypoint estimation."
      ],
      "metadata": {
        "id": "UFMekIFISxEp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A1wZkueRSrPv"
      },
      "outputs": [],
      "source": [
        "!pip install -U albumentations"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "id": "ar8CAlfzS6ia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Image(\"distanceImage.png\", width=400)"
      ],
      "metadata": {
        "id": "nm6R_xBnbBTv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset has two fields:\n",
        "\n",
        "image: a PIL PNG image object with uint8 data type.\n",
        "depth_map: a PIL Tiff image object with float32 data type which is the depth map of the image."
      ],
      "metadata": {
        "id": "ShLK10fJTCO4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset2 = load_dataset(\"sayakpaul/nyu_depth_v2\", split=\"validation\")"
      ],
      "metadata": {
        "id": "1xTnO-i47ZSd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "train_dataset = load_dataset(\"sayakpaul/nyu_depth_v2\", split=\"val\")\n"
      ],
      "metadata": {
        "id": "nSnGEkHqSy5C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example[\"image\"]"
      ],
      "metadata": {
        "id": "RwURgYVUTF3N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before we look at the depth map, we need to first convert its data type to uint8 using .convert('RGB') as PIL can’t display float32 images. Now take a look at its corresponding depth map:"
      ],
      "metadata": {
        "id": "XFmSL8mqTMH2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example[\"depth_map\"].convert(\"RGB\")\n"
      ],
      "metadata": {
        "id": "qZxTbC19TM3M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It’s all black! You’ll need to add some color to the depth map to visualize it properly. To do that, either we can apply color automatically during display using plt.imshow() or create a colored depth map using plt.cm and then display it. In this example, we have used the latter one, as we can save/write the colored depth map later. (the utility below is taken from the FastDepth repository)."
      ],
      "metadata": {
        "id": "EaPRnxsZTSmv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "cmap = plt.cm.viridis\n",
        "\n",
        "def colored_depthmap(depth, d_min=None, d_max=None):\n",
        "    if d_min is None:\n",
        "        d_min = np.min(depth)\n",
        "    if d_max is None:\n",
        "        d_max = np.max(depth)\n",
        "    depth_relative = (depth - d_min) / (d_max - d_min)\n",
        "    return 255 * cmap(depth_relative)[:,:,:3]\n",
        "\n",
        "def show_depthmap(depth_map):\n",
        "   if not isinstance(depth_map, np.ndarray):\n",
        "       depth_map = np.array(depth_map)\n",
        "   if depth_map.ndim == 3:\n",
        "       depth_map = depth_map.squeeze()\n",
        "\n",
        "   d_min = np.min(depth_map)\n",
        "   d_max = np.max(depth_map)\n",
        "   depth_map = colored_depthmap(depth_map, d_min, d_max)\n",
        "\n",
        "   plt.imshow(depth_map.astype(\"uint8\"))\n",
        "   plt.axis(\"off\")\n",
        "   plt.colorbar()\n",
        "   plt.show()"
      ],
      "metadata": {
        "id": "p3Q43_ylTTE5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_depthmap(example[\"depth_map\"])"
      ],
      "metadata": {
        "id": "7srvn8kx-Lu4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example2 = train_dataset[88]\n",
        "example2[\"image\"]"
      ],
      "metadata": {
        "id": "mruQJucx7gN7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_depthmap(example2[\"depth_map\"])"
      ],
      "metadata": {
        "id": "buX-pSkZ8RwF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can also visualize several different images and their corresponding depth maps."
      ],
      "metadata": {
        "id": "JgFmEvHZT2AC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def merge_into_row(input_image, depth_target):\n",
        "    if not isinstance(input_image, np.ndarray):\n",
        "        input_image = np.array(input_image)\n",
        "    d_min = np.min(depth_target)\n",
        "    d_max = np.max(depth_target)\n",
        "    depth_target_col = colored_depthmap(depth_target, d_min, d_max)\n",
        "    img_merge = np.hstack([input_image, depth_target_col])\n",
        "    return img_merge\n",
        "\n",
        "random_indices = np.random.choice(len(train_dataset), 9).tolist()\n",
        "plt.figure(figsize=(15, 6))\n",
        "for i, idx in enumerate(random_indices):\n",
        "    example = train_dataset[idx]\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    image_viz = merge_into_row(\n",
        "        example[\"image\"], example[\"depth_map\"]\n",
        "    )\n",
        "    plt.imshow(image_viz.astype(\"uint8\"))\n",
        "    plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "9d87eNCfTzov"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}